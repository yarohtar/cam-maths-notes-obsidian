Let $X$ and $Y$ be random variables. The mutual information is 
$$
I(X;Y)=H(X)-H(X|Y)
$$
i.e. the amount of information about $X$ conveyed by $Y$.
